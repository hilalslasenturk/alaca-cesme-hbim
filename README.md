# Scan-to-HBIM Framework

**AI-Assisted Automation of the Scan-to-HBIM Process for Cultural Heritage**

An open-source framework for converting 3D point cloud scans of heritage structures into semantically enriched HBIM (Historic Building Information Models) using cloud-based automation.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hilalslasenturk/alaca-cesme-hbim)

---

## Overview

This framework provides a complete pipeline for:
1. **Loading** raw point cloud data (.ply, .las, .e57)
2. **Preprocessing** with voxel downsampling and outlier removal
3. **Feature extraction** using geometric descriptors (Croce et al. 2021)
4. **Segmentation** with DBSCAN clustering
5. **Classification** using Random Forest (99.86% accuracy)
6. **Mesh reconstruction** with Poisson surface reconstruction
7. **IFC export** with semantic property sets

### Key Features

- **99.86% Classification Accuracy** using Y_normalized feature
- **IFC4 Schema** with IfcTriangulatedFaceSet geometry
- **3 Semantic Property Sets** for heritage documentation
- **Cloud-native** architecture (GCS + n8n + Colab)
- **Fully automated** pipeline (except Revit visualization)

---

## Architecture

### Cloud Infrastructure

```mermaid
flowchart LR
    subgraph Input
        A[ğŸ‘¤ User] -->|Upload .ply| B[(â˜ï¸ GCS)]
    end

    subgraph Orchestration
        B <-->|Trigger| C[âš¡ n8n]
        C <-->|Execute| D[ğŸ““ Colab]
    end

    subgraph Processing
        D --> E[Phase 1: Load]
        E --> F[Phase 2: Preprocess]
        F --> G[Phase 3: Features]
        G --> H[Phase 4: Segment]
        H --> I[Phase 5: Classify]
        I --> J[Phase 6: Mesh]
        J --> K[Phase 7: IFC]
    end

    subgraph Output
        K -->|Export| L[(â˜ï¸ GCS)]
        L -->|Download| M[ğŸ“¦ IFC File]
        M -->|Manual| N[ğŸ›ï¸ Revit]
    end

    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style N fill:#fce4ec
```

### Pipeline Flow

```mermaid
flowchart TB
    subgraph Phase1[" 1ï¸âƒ£ Load "]
        A1[Raw Point Cloud<br>.ply / .las / .e57] --> A2[Validate & Load]
    end

    subgraph Phase2[" 2ï¸âƒ£ Preprocess "]
        A2 --> B1[Voxel Downsampling<br>0.01m]
        B1 --> B2[SOR Outlier Removal]
        B2 --> B3[Normal Estimation]
    end

    subgraph Phase3[" 3ï¸âƒ£ Features "]
        B3 --> C1[Geometric Features<br>9 per scale Ã— 3 scales]
        C1 --> C2[Position Features<br>X, Y, Z normalized]
        C2 --> C3[30 Total Features]
    end

    subgraph Phase4[" 4ï¸âƒ£ Segment "]
        C3 --> D1[DBSCAN Clustering<br>eps=0.05m]
    end

    subgraph Phase5[" 5ï¸âƒ£ Classify "]
        D1 --> E1[Random Forest<br>100 trees]
        E1 --> E2[ğŸ¯ 99.86% Accuracy<br>Y_normalized key feature]
    end

    subgraph Phase6[" 6ï¸âƒ£ Mesh "]
        E2 --> F1[Poisson Reconstruction<br>depth=10]
        F1 --> F2[Per-element Trimming]
    end

    subgraph Phase7[" 7ï¸âƒ£ IFC "]
        F2 --> G1[IFC4 Schema]
        G1 --> G2[Semantic Property Sets]
        G2 --> G3[ğŸ“„ Final IFC Model]
    end

    style Phase1 fill:#e3f2fd
    style Phase2 fill:#e8f5e9
    style Phase3 fill:#fff3e0
    style Phase4 fill:#fce4ec
    style Phase5 fill:#f3e5f5
    style Phase6 fill:#e0f2f1
    style Phase7 fill:#fffde7
    style E2 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
```

---

## Pipeline Phases

| Phase | Description | Output |
|-------|-------------|--------|
| 1. Load | Load & validate point cloud | `01_raw/` |
| 2. Preprocess | Voxel, SOR, Normal estimation | `02_preprocessed/` |
| 3. Features | 30 geometric features + Y_normalized | `03_features/` |
| 4. Segment | DBSCAN clustering | `04_segmentation/` |
| 5. Classify | Random Forest (99.86%) | `05_classification/` |
| 6. Mesh | Poisson reconstruction | `06_mesh/` |
| 7. IFC | Semantic IFC4 export | `07_ifc/` |

---

## Quick Start

### Option 1: Google Colab (Recommended)

1. Open any notebook in Colab:
   - [01_Load.ipynb](notebooks/01_Load.ipynb)
   - [02_Preprocess.ipynb](notebooks/02_Preprocess.ipynb)
   - etc.

2. Configure GCS bucket name and version
3. Run all cells

### Option 2: Local Installation

```bash
# Clone repository
git clone https://github.com/hilalslasenturk/alaca-cesme-hbim.git
cd alaca-cesme-hbim

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run pipeline
python src/run_pipeline.py --input your_pointcloud.ply
```

### Option 3: n8n Automation

1. Import `n8n/scan_to_hbim_v6_workflow.json` into n8n
2. Configure GCS credentials
3. Trigger via webhook

---

## Project Structure

```
alaca-cesme-hbim/
â”‚
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ LICENSE                   # MIT License
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore               # Git ignore rules
â”‚
â”œâ”€â”€ notebooks/               # Google Colab notebooks
â”‚   â”œâ”€â”€ 01_Load.ipynb
â”‚   â”œâ”€â”€ 02_Preprocess.ipynb
â”‚   â”œâ”€â”€ 03_Features.ipynb
â”‚   â”œâ”€â”€ 04_Segment.ipynb
â”‚   â”œâ”€â”€ 05_Classify.ipynb
â”‚   â”œâ”€â”€ 06_Mesh.ipynb
â”‚   â””â”€â”€ 07_IFC.ipynb
â”‚
â”œâ”€â”€ src/                     # Python source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ phase1_load.py
â”‚   â”œâ”€â”€ phase2_preprocess.py
â”‚   â”œâ”€â”€ phase3_features.py
â”‚   â”œâ”€â”€ phase4_segment.py
â”‚   â”œâ”€â”€ phase5_classify.py
â”‚   â”œâ”€â”€ phase6_mesh.py
â”‚   â”œâ”€â”€ phase7_ifc.py
â”‚   â””â”€â”€ run_pipeline.py      # Full pipeline runner
â”‚
â”œâ”€â”€ n8n/                     # n8n workflow exports
â”‚   â””â”€â”€ scan_to_hbim_v6_workflow.json
â”‚
â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ heritage_metadata.json
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ METHODOLOGY.md
â”‚   â”œâ”€â”€ GCS_SETUP.md
â”‚   â””â”€â”€ N8N_SETUP.md
â”‚
â””â”€â”€ examples/                # Example outputs
    â””â”€â”€ sample_ifc/
```

---

## Heritage Classes

| Class | Turkish | IFC Entity | Description |
|-------|---------|------------|-------------|
| zemin | Zemin | IfcSlab | Ground/floor surface |
| seki | Seki | IfcSlab | Marble platform |
| ana_cephe | Ana Cephe | IfcWall | Main facade wall |
| kemer | Kemer | IfcBuildingElementProxy | Arch structure |
| sacak | SaÃ§ak | IfcRoof | Cornice/eaves |

---

## Semantic Property Sets

### Pset_YapiKimligi (Building Identity)
- YapiAdi, YapimTarihi, HicriTarih, Donem, Bani, YapiTipi, Konum

### Pset_ElemanBilgisi (Element Information)
- ElemanAdi_TR, ElemanAdi_EN, IFCSinifi, VertexSayisi, UcgenSayisi

### Pset_KorumaDurumu (Conservation Status)
- TescilDurumu, SonRestorasyon, MevcutDurum, OzgunIslev, GuncelIslev

---

## Key Achievement: Y_normalized Feature

The **Y_normalized** feature (depth from facade) is the key to achieving 99.86% classification accuracy:

```python
# Y coordinate distinguishes elements by depth
y_coords = points[:, 1]
y_normalized = (y_coords - y_coords.min()) / (y_coords.max() - y_coords.min())

# Kemer (arch): Y â‰ˆ 0.3-0.5 (front)
# Ana Cephe (wall): Y â‰ˆ 0.1-0.3 (back)
# Seki (platform): Y â‰ˆ 0.6-0.8 (very front)
```

---

## Case Study: Alaca Ã‡eÅŸmesi

This framework was developed and tested on **Alaca Ã‡eÅŸmesi** (Alaca Fountain), a 16th-century Ottoman fountain in Istanbul:

- **Construction Date:** 1586 (H.995)
- **Period:** Classical Ottoman (III. Murad)
- **Location:** EyÃ¼psultan, Istanbul, Turkey
- **Raw Points:** 9.2 million
- **Final IFC Size:** ~80 MB

---

## Requirements

- Python 3.8+
- Open3D 0.17+
- NumPy, SciPy, scikit-learn
- ifcopenshell
- google-cloud-storage (for cloud execution)

See [requirements.txt](requirements.txt) for full list.

---

## References

1. **Croce, V. et al. (2021)** - "From Survey to Semantic Representation for Cultural Heritage", ISPRS Int. J. Geo-Inf.

2. **Poux, F. (2025)** - "3D Data Science with Python"

3. **Gil, J. et al. (2024)** - Heritage ML comparison study

---

## License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

---

## Citation

If you use this framework in your research, please cite:

```bibtex
@software{scan_to_hbim_2026,
  author = {ÅentÃ¼rk, Hilal SÄ±la},
  title = {Scan-to-HBIM Framework: AI-Assisted Automation for Cultural Heritage},
  year = {2026},
  url = {https://github.com/hilalslasenturk/alaca-cesme-hbim}
}
```

---

## Contact

- **Author:** Hilal SÄ±la ÅentÃ¼rk
- **Email:** hilalslasenturk@gmail.com
- **University:** Ankara YÄ±ldÄ±rÄ±m BeyazÄ±t Ãœniversitesi

### Supervisors

- **Dr. Ã–ÄŸr. Ãœyesi Cemile Feyzan ÅimÅŸek** - Thesis Advisor
- **Ã–ÄŸr. GÃ¶r. Dr. Ã–mer Faruk Pamak** - Co-Advisor

---

*Developed as part of Master's Thesis: "AI-Assisted Automation of the Scan-to-HBIM Process for Cultural Heritage: Development of an Open Framework"*
