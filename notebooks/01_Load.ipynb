{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Load & Validate Point Cloud\n",
        "## Alaca Cesmesi Scan-to-HBIM V6 Pipeline\n",
        "\n",
        "This notebook loads the raw point cloud from GCS and performs initial validation.\n",
        "\n",
        "**Input:** `gs://alaca-cesme-hbim-v6/raw/pointcloud/*.ply`  \n",
        "**Output:** `gs://alaca-cesme-hbim-v6/processed/v{N}/01_raw/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q open3d google-cloud-storage numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "\n",
        "print(f\"Open3D version: {o3d.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GCS Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Authenticate with Google Cloud\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Configuration\n",
        "BUCKET_NAME = \"alaca-cesme-hbim-v6\"\n",
        "PROJECT_ID = \"concrete-racer-470219-h8\"\n",
        "VERSION = \"v1\"  # Change for each run\n",
        "\n",
        "# Paths\n",
        "RAW_INPUT_PATH = \"raw/pointcloud/alaca_cesme_raw.ply\"\n",
        "OUTPUT_BASE = f\"processed/{VERSION}/01_raw/\"\n",
        "\n",
        "# Local temp paths\n",
        "LOCAL_INPUT = \"/content/input.ply\"\n",
        "LOCAL_OUTPUT_PLY = \"/content/01_raw_pointcloud.ply\"\n",
        "LOCAL_OUTPUT_JSON = \"/content/01_raw_stats.json\"\n",
        "\n",
        "print(f\"Bucket: {BUCKET_NAME}\")\n",
        "print(f\"Version: {VERSION}\")\n",
        "print(f\"Input: {RAW_INPUT_PATH}\")\n",
        "print(f\"Output: {OUTPUT_BASE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download from GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_from_gcs(bucket_name, blob_name, local_path):\n",
        "    \"\"\"Download file from GCS bucket.\"\"\"\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    \n",
        "    print(f\"Downloading: gs://{bucket_name}/{blob_name}\")\n",
        "    blob.download_to_filename(local_path)\n",
        "    size_mb = os.path.getsize(local_path) / (1024 * 1024)\n",
        "    print(f\"Downloaded: {local_path} ({size_mb:.1f} MB)\")\n",
        "    return local_path\n",
        "\n",
        "# Download raw point cloud\n",
        "download_from_gcs(BUCKET_NAME, RAW_INPUT_PATH, LOCAL_INPUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Point Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_point_cloud(file_path):\n",
        "    \"\"\"\n",
        "    Load a point cloud from file.\n",
        "    \n",
        "    Open3D's read_point_cloud() automatically detects file format.\n",
        "    For large files (>100MB), binary formats are significantly faster.\n",
        "    \"\"\"\n",
        "    print(f\"Loading point cloud: {file_path}\")\n",
        "    pcd = o3d.io.read_point_cloud(file_path)\n",
        "    print(f\"Points loaded: {len(pcd.points):,}\")\n",
        "    return pcd\n",
        "\n",
        "# Load\n",
        "pcd = load_point_cloud(LOCAL_INPUT)\n",
        "print(f\"\\nPoint cloud loaded with {len(pcd.points):,} points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Validate Point Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_point_cloud(pcd, input_filename):\n",
        "    \"\"\"\n",
        "    Validate and analyze point cloud properties.\n",
        "    \n",
        "    Key properties to check:\n",
        "        1. Point count: Should be > 0\n",
        "        2. Colors: RGB values (0-1 in Open3D)\n",
        "        3. Normals: Unit vectors for surface orientation\n",
        "        4. Bounding box: Spatial extent of data\n",
        "    \"\"\"\n",
        "    points = np.asarray(pcd.points)\n",
        "    \n",
        "    if len(points) == 0:\n",
        "        raise ValueError(\"Point cloud is empty!\")\n",
        "    \n",
        "    # Compute bounding box\n",
        "    bbox = pcd.get_axis_aligned_bounding_box()\n",
        "    min_bound = bbox.get_min_bound()\n",
        "    max_bound = bbox.get_max_bound()\n",
        "    dimensions = max_bound - min_bound\n",
        "    center = bbox.get_center()\n",
        "    \n",
        "    # Check attributes\n",
        "    has_colors = pcd.has_colors()\n",
        "    has_normals = pcd.has_normals()\n",
        "    \n",
        "    stats = {\n",
        "        \"file_name\": input_filename,\n",
        "        \"point_count\": len(points),\n",
        "        \"point_count_formatted\": f\"{len(points):,}\",\n",
        "        \"bounding_box\": {\n",
        "            \"min\": min_bound.tolist(),\n",
        "            \"max\": max_bound.tolist(),\n",
        "            \"dimensions\": dimensions.tolist(),\n",
        "            \"center\": center.tolist()\n",
        "        },\n",
        "        \"dimensions_formatted\": {\n",
        "            \"width_x\": f\"{dimensions[0]:.3f}m\",\n",
        "            \"depth_y\": f\"{dimensions[1]:.3f}m\",\n",
        "            \"height_z\": f\"{dimensions[2]:.3f}m\"\n",
        "        },\n",
        "        \"has_colors\": has_colors,\n",
        "        \"has_normals\": has_normals,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"pipeline_version\": \"v6\",\n",
        "        \"phase\": \"01_load\"\n",
        "    }\n",
        "    \n",
        "    return stats\n",
        "\n",
        "# Validate\n",
        "stats = validate_point_cloud(pcd, os.path.basename(RAW_INPUT_PATH))\n",
        "\n",
        "# Print report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"POINT CLOUD VALIDATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nFile: {stats['file_name']}\")\n",
        "print(f\"Points: {stats['point_count_formatted']}\")\n",
        "print(f\"\\nBounding Box:\")\n",
        "print(f\"  Width (X):  {stats['dimensions_formatted']['width_x']}\")\n",
        "print(f\"  Depth (Y):  {stats['dimensions_formatted']['depth_y']}\")\n",
        "print(f\"  Height (Z): {stats['dimensions_formatted']['height_z']}\")\n",
        "print(f\"\\nAttributes:\")\n",
        "print(f\"  Has Colors:  {'Yes' if stats['has_colors'] else 'No'}\")\n",
        "print(f\"  Has Normals: {'Yes' if stats['has_normals'] else 'No (will compute)'}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Outputs Locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save point cloud\n",
        "o3d.io.write_point_cloud(LOCAL_OUTPUT_PLY, pcd, write_ascii=False, compressed=False)\n",
        "print(f\"Saved: {LOCAL_OUTPUT_PLY}\")\n",
        "\n",
        "# Save statistics\n",
        "with open(LOCAL_OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
        "    json.dump(stats, f, indent=2, ensure_ascii=False)\n",
        "print(f\"Saved: {LOCAL_OUTPUT_JSON}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Upload to GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upload_to_gcs(bucket_name, local_path, blob_name):\n",
        "    \"\"\"Upload file to GCS bucket.\"\"\"\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    \n",
        "    print(f\"Uploading: {local_path} -> gs://{bucket_name}/{blob_name}\")\n",
        "    blob.upload_from_filename(local_path)\n",
        "    size_mb = os.path.getsize(local_path) / (1024 * 1024)\n",
        "    print(f\"Uploaded: {size_mb:.1f} MB\")\n",
        "    return f\"gs://{bucket_name}/{blob_name}\"\n",
        "\n",
        "# Upload outputs\n",
        "ply_gcs_path = upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_PLY, f\"{OUTPUT_BASE}01_raw_pointcloud.ply\")\n",
        "json_gcs_path = upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_JSON, f\"{OUTPUT_BASE}01_raw_stats.json\")\n",
        "\n",
        "print(f\"\\nOutputs uploaded to GCS:\")\n",
        "print(f\"  PLY:  {ply_gcs_path}\")\n",
        "print(f\"  JSON: {json_gcs_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Return Status (for n8n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare status response for n8n webhook\n",
        "status = {\n",
        "    \"phase\": \"01_load\",\n",
        "    \"status\": \"success\",\n",
        "    \"version\": VERSION,\n",
        "    \"outputs\": {\n",
        "        \"pointcloud\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}01_raw_pointcloud.ply\",\n",
        "        \"stats\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}01_raw_stats.json\"\n",
        "    },\n",
        "    \"metrics\": {\n",
        "        \"point_count\": stats[\"point_count\"],\n",
        "        \"has_colors\": stats[\"has_colors\"],\n",
        "        \"has_normals\": stats[\"has_normals\"],\n",
        "        \"dimensions\": stats[\"dimensions_formatted\"]\n",
        "    },\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"next_phase\": \"02_preprocess\"\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 1 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(status, indent=2))"
      ]
    }
  ]
}
