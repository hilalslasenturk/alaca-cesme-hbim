{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Feature Extraction (Croce et al. 2021)\n",
        "## Alaca Cesmesi Scan-to-HBIM V6 Pipeline\n",
        "\n",
        "Extracts 30 geometric features:\n",
        "- 9 eigenvalue-based features x 3 scales = 27 features\n",
        "- 3 position features: X, **Y**, Z normalized\n",
        "\n",
        "**CRITICAL: Y_normalized is the key feature for 99.86% accuracy!**\n",
        "\n",
        "**Input:** `gs://alaca-cesme-hbim-v6/processed/v{N}/02_preprocessed/`  \n",
        "**Output:** `gs://alaca-cesme-hbim-v6/processed/v{N}/03_features/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q open3d google-cloud-storage numpy scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Configuration\n",
        "BUCKET_NAME = \"alaca-cesme-hbim-v6\"\n",
        "PROJECT_ID = \"concrete-racer-470219-h8\"\n",
        "VERSION = \"v1\"\n",
        "\n",
        "# Feature extraction parameters (Croce et al. 2021)\n",
        "RADII = [0.03, 0.06, 0.10]  # Multi-scale radii\n",
        "FEATURE_NAMES = [\n",
        "    \"linearity\", \"planarity\", \"sphericity\", \"omnivariance\",\n",
        "    \"eigenentropy\", \"surface_variation\", \"sum_eigenvalues\",\n",
        "    \"anisotropy\", \"verticality\"\n",
        "]\n",
        "\n",
        "# Paths\n",
        "INPUT_PATH = f\"processed/{VERSION}/02_preprocessed/02_preprocessed.ply\"\n",
        "OUTPUT_BASE = f\"processed/{VERSION}/03_features/\"\n",
        "\n",
        "LOCAL_INPUT = \"/content/input.ply\"\n",
        "LOCAL_OUTPUT_NPY = \"/content/03_features.npy\"\n",
        "LOCAL_OUTPUT_JSON = \"/content/03_features_stats.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GCS functions\n",
        "def download_from_gcs(bucket_name, blob_name, local_path):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.download_to_filename(local_path)\n",
        "    print(f\"Downloaded: {blob_name}\")\n",
        "    return local_path\n",
        "\n",
        "def upload_to_gcs(bucket_name, local_path, blob_name):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_filename(local_path)\n",
        "    print(f\"Uploaded: {blob_name}\")\n",
        "    return f\"gs://{bucket_name}/{blob_name}\"\n",
        "\n",
        "# Download input\n",
        "download_from_gcs(BUCKET_NAME, INPUT_PATH, LOCAL_INPUT)\n",
        "pcd = o3d.io.read_point_cloud(LOCAL_INPUT)\n",
        "points = np.asarray(pcd.points)\n",
        "normals = np.asarray(pcd.normals)\n",
        "n_points = len(points)\n",
        "print(f\"Loaded: {n_points:,} points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_eigenvalues(points, kdtree, radius, min_neighbors=5):\n",
        "    \"\"\"\n",
        "    Compute eigenvalues for each point using PCA of local neighborhood.\n",
        "    \"\"\"\n",
        "    n_points = len(points)\n",
        "    eigenvalues = np.zeros((n_points, 3))\n",
        "    eps = 1e-10\n",
        "    \n",
        "    for i in range(n_points):\n",
        "        indices = kdtree.query_ball_point(points[i], radius)\n",
        "        \n",
        "        if len(indices) < min_neighbors:\n",
        "            eigenvalues[i] = [1.0, 1.0, 1.0]\n",
        "            continue\n",
        "        \n",
        "        neighbors = points[indices]\n",
        "        centered = neighbors - neighbors.mean(axis=0)\n",
        "        cov = np.cov(centered.T)\n",
        "        \n",
        "        if cov.ndim < 2:\n",
        "            eigenvalues[i] = [1.0, 0.0, 0.0]\n",
        "            continue\n",
        "        \n",
        "        eigvals = np.linalg.eigvalsh(cov)\n",
        "        eigvals = np.sort(eigvals)[::-1]  # Descending\n",
        "        eigvals = np.maximum(eigvals, eps)\n",
        "        eigenvalues[i] = eigvals\n",
        "    \n",
        "    return eigenvalues\n",
        "\n",
        "\n",
        "def compute_geometric_features(eigenvalues, normals):\n",
        "    \"\"\"\n",
        "    Compute 9 geometric features from eigenvalues and normals.\n",
        "    \"\"\"\n",
        "    n_points = len(eigenvalues)\n",
        "    features = np.zeros((n_points, 9))\n",
        "    eps = 1e-10\n",
        "    \n",
        "    l1, l2, l3 = eigenvalues[:, 0], eigenvalues[:, 1], eigenvalues[:, 2]\n",
        "    l_sum = l1 + l2 + l3 + eps\n",
        "    \n",
        "    # 9 features (Croce et al. 2021)\n",
        "    features[:, 0] = (l1 - l2) / (l1 + eps)  # Linearity\n",
        "    features[:, 1] = (l2 - l3) / (l1 + eps)  # Planarity\n",
        "    features[:, 2] = l3 / (l1 + eps)          # Sphericity\n",
        "    features[:, 3] = np.cbrt(l1 * l2 * l3 + eps)  # Omnivariance\n",
        "    \n",
        "    l_norm = eigenvalues / l_sum[:, np.newaxis]\n",
        "    l_norm = np.maximum(l_norm, eps)\n",
        "    features[:, 4] = -np.sum(l_norm * np.log(l_norm), axis=1)  # Eigenentropy\n",
        "    \n",
        "    features[:, 5] = l3 / l_sum  # Surface variation\n",
        "    features[:, 6] = l_sum       # Sum eigenvalues\n",
        "    features[:, 7] = (l1 - l3) / (l1 + eps)  # Anisotropy\n",
        "    features[:, 8] = 1.0 - np.abs(normals[:, 2])  # Verticality\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Build KD-tree once\n",
        "print(\"Building KD-tree...\")\n",
        "kdtree = cKDTree(points)\n",
        "\n",
        "# Extract features at each scale\n",
        "n_features_per_scale = 9\n",
        "all_features = np.zeros((n_points, n_features_per_scale * len(RADII)))\n",
        "\n",
        "for scale_idx, radius in enumerate(RADII):\n",
        "    print(f\"\\n[Scale {scale_idx + 1}/{len(RADII)}] radius = {radius}m\")\n",
        "    \n",
        "    eigenvalues = compute_eigenvalues(points, kdtree, radius)\n",
        "    features = compute_geometric_features(eigenvalues, normals)\n",
        "    \n",
        "    start_col = scale_idx * n_features_per_scale\n",
        "    end_col = start_col + n_features_per_scale\n",
        "    all_features[:, start_col:end_col] = features\n",
        "    \n",
        "    print(f\"  Computed {n_features_per_scale} features\")\n",
        "\n",
        "print(f\"\\nGeometric features shape: {all_features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add X, Y, Z normalized - CRITICAL FOR ACCURACY!\n",
        "print(\"\\nAdding normalized position features (X, Y, Z)...\")\n",
        "\n",
        "# X normalized\n",
        "x_coords = points[:, 0]\n",
        "x_normalized = (x_coords - x_coords.min()) / (x_coords.max() - x_coords.min() + 1e-10)\n",
        "\n",
        "# Y normalized - THE KEY FEATURE FOR 99.86% ACCURACY!\n",
        "y_coords = points[:, 1]\n",
        "y_normalized = (y_coords - y_coords.min()) / (y_coords.max() - y_coords.min() + 1e-10)\n",
        "\n",
        "# Z normalized\n",
        "z_coords = points[:, 2]\n",
        "z_normalized = (z_coords - z_coords.min()) / (z_coords.max() - z_coords.min() + 1e-10)\n",
        "\n",
        "# Combine all features\n",
        "features = np.column_stack([all_features, x_normalized, y_normalized, z_normalized])\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"\\nFinal feature shape: {features.shape}\")\n",
        "print(f\"Total features: {features.shape[1]} (27 geometric + 3 position)\")\n",
        "print(f\"Processing time: {elapsed_time:.1f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create feature names\n",
        "feature_names = []\n",
        "for radius in RADII:\n",
        "    for name in FEATURE_NAMES:\n",
        "        feature_names.append(f\"{name}_r{radius:.2f}\")\n",
        "feature_names.extend([\"x_normalized\", \"y_normalized\", \"z_normalized\"])\n",
        "\n",
        "# Compute statistics\n",
        "feature_stats = {}\n",
        "for i, name in enumerate(feature_names):\n",
        "    col = features[:, i]\n",
        "    feature_stats[name] = {\n",
        "        \"min\": float(np.min(col)),\n",
        "        \"max\": float(np.max(col)),\n",
        "        \"mean\": float(np.mean(col)),\n",
        "        \"std\": float(np.std(col))\n",
        "    }\n",
        "\n",
        "stats = {\n",
        "    \"phase\": \"03_features\",\n",
        "    \"n_points\": n_points,\n",
        "    \"n_features\": features.shape[1],\n",
        "    \"feature_names\": feature_names,\n",
        "    \"radii\": RADII,\n",
        "    \"y_normalized_note\": \"CRITICAL: Y_normalized is the key feature for 99.86% accuracy\",\n",
        "    \"feature_statistics\": feature_stats,\n",
        "    \"processing_time_sec\": elapsed_time,\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"pipeline_version\": \"v6\"\n",
        "}\n",
        "\n",
        "# Save locally\n",
        "np.save(LOCAL_OUTPUT_NPY, features)\n",
        "with open(LOCAL_OUTPUT_JSON, 'w') as f:\n",
        "    json.dump(stats, f, indent=2)\n",
        "print(\"Saved outputs locally\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload to GCS\n",
        "upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_NPY, f\"{OUTPUT_BASE}03_features.npy\")\n",
        "upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_JSON, f\"{OUTPUT_BASE}03_features_stats.json\")\n",
        "\n",
        "# Status for n8n\n",
        "status = {\n",
        "    \"phase\": \"03_features\",\n",
        "    \"status\": \"success\",\n",
        "    \"version\": VERSION,\n",
        "    \"outputs\": {\n",
        "        \"features\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}03_features.npy\",\n",
        "        \"stats\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}03_features_stats.json\"\n",
        "    },\n",
        "    \"metrics\": {\n",
        "        \"n_points\": n_points,\n",
        "        \"n_features\": features.shape[1],\n",
        "        \"radii\": RADII,\n",
        "        \"processing_time\": f\"{elapsed_time:.1f}s\"\n",
        "    },\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"next_phase\": \"04_segment\"\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 3 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(status, indent=2))"
      ]
    }
  ]
}
