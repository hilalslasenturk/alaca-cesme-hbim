{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 4: Segmentation (DBSCAN)\n",
        "## Alaca Cesmesi Scan-to-HBIM V6 Pipeline\n",
        "\n",
        "Segments the point cloud using DBSCAN clustering.\n",
        "\n",
        "**Input:** `gs://alaca-cesme-hbim-v6/processed/v{N}/02_preprocessed/`  \n",
        "**Output:** `gs://alaca-cesme-hbim-v6/processed/v{N}/04_segmentation/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q open3d google-cloud-storage numpy scipy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Configuration\n",
        "BUCKET_NAME = \"alaca-cesme-hbim-v6\"\n",
        "PROJECT_ID = \"concrete-racer-470219-h8\"\n",
        "VERSION = \"v1\"\n",
        "\n",
        "# DBSCAN parameters\n",
        "DBSCAN_EPS = 0.05  # 5cm neighborhood radius\n",
        "DBSCAN_MIN_SAMPLES = 50\n",
        "MIN_SEGMENT_POINTS = 100  # Remove tiny segments\n",
        "\n",
        "# Paths\n",
        "INPUT_PLY_PATH = f\"processed/{VERSION}/02_preprocessed/02_preprocessed.ply\"\n",
        "OUTPUT_BASE = f\"processed/{VERSION}/04_segmentation/\"\n",
        "\n",
        "LOCAL_INPUT = \"/content/input.ply\"\n",
        "LOCAL_OUTPUT_PLY = \"/content/04_segmented.ply\"\n",
        "LOCAL_OUTPUT_LABELS = \"/content/04_segment_labels.npy\"\n",
        "LOCAL_OUTPUT_JSON = \"/content/04_segments_metadata.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GCS functions\n",
        "def download_from_gcs(bucket_name, blob_name, local_path):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.download_to_filename(local_path)\n",
        "    print(f\"Downloaded: {blob_name}\")\n",
        "    return local_path\n",
        "\n",
        "def upload_to_gcs(bucket_name, local_path, blob_name):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_filename(local_path)\n",
        "    print(f\"Uploaded: {blob_name}\")\n",
        "    return f\"gs://{bucket_name}/{blob_name}\"\n",
        "\n",
        "# Download input\n",
        "download_from_gcs(BUCKET_NAME, INPUT_PLY_PATH, LOCAL_INPUT)\n",
        "pcd = o3d.io.read_point_cloud(LOCAL_INPUT)\n",
        "points = np.asarray(pcd.points)\n",
        "n_points = len(points)\n",
        "print(f\"Loaded: {n_points:,} points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Run DBSCAN\n",
        "print(f\"\\nRunning DBSCAN (eps={DBSCAN_EPS}, min_samples={DBSCAN_MIN_SAMPLES})...\")\n",
        "clustering = DBSCAN(eps=DBSCAN_EPS, min_samples=DBSCAN_MIN_SAMPLES, n_jobs=-1)\n",
        "labels = clustering.fit_predict(points)\n",
        "\n",
        "# Statistics\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_noise = np.sum(labels == -1)\n",
        "\n",
        "print(f\"\\nDBSCAN Results:\")\n",
        "print(f\"  Clusters found: {n_clusters}\")\n",
        "print(f\"  Noise points: {n_noise:,} ({100*n_noise/n_points:.1f}%)\")\n",
        "\n",
        "# Remove small segments\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "small_segments = unique_labels[(counts < MIN_SEGMENT_POINTS) & (unique_labels != -1)]\n",
        "for seg in small_segments:\n",
        "    labels[labels == seg] = -1\n",
        "    \n",
        "n_clusters_final = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "print(f\"  After filtering: {n_clusters_final} segments (removed {n_clusters - n_clusters_final} small ones)\")\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"\\nProcessing time: {elapsed_time:.1f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Color segments for visualization\n",
        "max_label = labels.max()\n",
        "colors = np.zeros((n_points, 3))\n",
        "np.random.seed(42)\n",
        "\n",
        "for label in range(max_label + 1):\n",
        "    mask = labels == label\n",
        "    colors[mask] = np.random.rand(3)\n",
        "    \n",
        "# Noise points = gray\n",
        "colors[labels == -1] = [0.5, 0.5, 0.5]\n",
        "\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "print(f\"Colored {max_label + 1} segments + noise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute segment statistics\n",
        "segment_info = []\n",
        "for label in range(max_label + 1):\n",
        "    mask = labels == label\n",
        "    segment_points = points[mask]\n",
        "    \n",
        "    if len(segment_points) > 0:\n",
        "        bbox_min = segment_points.min(axis=0)\n",
        "        bbox_max = segment_points.max(axis=0)\n",
        "        \n",
        "        segment_info.append({\n",
        "            \"id\": int(label),\n",
        "            \"point_count\": int(np.sum(mask)),\n",
        "            \"bbox_min\": bbox_min.tolist(),\n",
        "            \"bbox_max\": bbox_max.tolist(),\n",
        "            \"centroid\": segment_points.mean(axis=0).tolist()\n",
        "        })\n",
        "\n",
        "stats = {\n",
        "    \"phase\": \"04_segmentation\",\n",
        "    \"n_points\": n_points,\n",
        "    \"n_segments\": n_clusters_final,\n",
        "    \"n_noise_points\": int(np.sum(labels == -1)),\n",
        "    \"dbscan_params\": {\n",
        "        \"eps\": DBSCAN_EPS,\n",
        "        \"min_samples\": DBSCAN_MIN_SAMPLES,\n",
        "        \"min_segment_points\": MIN_SEGMENT_POINTS\n",
        "    },\n",
        "    \"segments\": segment_info,\n",
        "    \"processing_time_sec\": elapsed_time,\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"pipeline_version\": \"v6\"\n",
        "}\n",
        "\n",
        "# Save locally\n",
        "o3d.io.write_point_cloud(LOCAL_OUTPUT_PLY, pcd)\n",
        "np.save(LOCAL_OUTPUT_LABELS, labels)\n",
        "with open(LOCAL_OUTPUT_JSON, 'w') as f:\n",
        "    json.dump(stats, f, indent=2)\n",
        "print(\"Saved outputs locally\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload to GCS\n",
        "upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_PLY, f\"{OUTPUT_BASE}04_segmented.ply\")\n",
        "upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_LABELS, f\"{OUTPUT_BASE}04_segment_labels.npy\")\n",
        "upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_JSON, f\"{OUTPUT_BASE}04_segments_metadata.json\")\n",
        "\n",
        "# Status for n8n\n",
        "status = {\n",
        "    \"phase\": \"04_segment\",\n",
        "    \"status\": \"success\",\n",
        "    \"version\": VERSION,\n",
        "    \"outputs\": {\n",
        "        \"segmented_ply\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}04_segmented.ply\",\n",
        "        \"labels\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}04_segment_labels.npy\",\n",
        "        \"metadata\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}04_segments_metadata.json\"\n",
        "    },\n",
        "    \"metrics\": {\n",
        "        \"n_segments\": n_clusters_final,\n",
        "        \"n_noise_points\": int(np.sum(labels == -1)),\n",
        "        \"processing_time\": f\"{elapsed_time:.1f}s\"\n",
        "    },\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"next_phase\": \"05_classify\"\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 4 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(status, indent=2))"
      ]
    }
  ]
}
