{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 5: Classification (Random Forest - 99.86% Accuracy)\n",
        "## Alaca Cesmesi Scan-to-HBIM V6 Pipeline\n",
        "\n",
        "Classifies point cloud into 5 heritage classes using Random Forest.\n",
        "\n",
        "**Classes:**\n",
        "- `zemin` - Ground (IfcSlab)\n",
        "- `seki` - Platform (IfcSlab)\n",
        "- `ana_cephe` - Main Wall (IfcWall)\n",
        "- `kemer` - Arch (IfcBuildingElementProxy)\n",
        "- `sacak` - Cornice (IfcRoof)\n",
        "\n",
        "**Input:** Features from Phase 3, Segments from Phase 4  \n",
        "**Output:** `gs://alaca-cesme-hbim-v6/processed/v{N}/05_classification/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q open3d google-cloud-storage numpy scipy scikit-learn joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Configuration\n",
        "BUCKET_NAME = \"alaca-cesme-hbim-v6\"\n",
        "PROJECT_ID = \"concrete-racer-470219-h8\"\n",
        "VERSION = \"v1\"\n",
        "\n",
        "# Heritage classes\n",
        "CLASSES = {\n",
        "    0: {\"name\": \"zemin\", \"name_tr\": \"Zemin\", \"color\": [34, 139, 34]},\n",
        "    1: {\"name\": \"seki\", \"name_tr\": \"Seki\", \"color\": [176, 196, 222]},\n",
        "    2: {\"name\": \"ana_cephe\", \"name_tr\": \"Ana Cephe\", \"color\": [139, 90, 43]},\n",
        "    3: {\"name\": \"kemer\", \"name_tr\": \"Kemer\", \"color\": [178, 34, 34]},\n",
        "    4: {\"name\": \"sacak\", \"name_tr\": \"Sacak\", \"color\": [210, 180, 140]}\n",
        "}\n",
        "\n",
        "# Paths\n",
        "INPUT_PLY_PATH = f\"processed/{VERSION}/02_preprocessed/02_preprocessed.ply\"\n",
        "INPUT_FEATURES_PATH = f\"processed/{VERSION}/03_features/03_features.npy\"\n",
        "OUTPUT_BASE = f\"processed/{VERSION}/05_classification/\"\n",
        "\n",
        "LOCAL_INPUT_PLY = \"/content/input.ply\"\n",
        "LOCAL_INPUT_FEATURES = \"/content/features.npy\"\n",
        "LOCAL_OUTPUT_MODEL = \"/content/05_model.joblib\"\n",
        "LOCAL_OUTPUT_JSON = \"/content/05_classification_metrics.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GCS functions\n",
        "def download_from_gcs(bucket_name, blob_name, local_path):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.download_to_filename(local_path)\n",
        "    print(f\"Downloaded: {blob_name}\")\n",
        "    return local_path\n",
        "\n",
        "def upload_to_gcs(bucket_name, local_path, blob_name):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_filename(local_path)\n",
        "    print(f\"Uploaded: {blob_name}\")\n",
        "    return f\"gs://{bucket_name}/{blob_name}\"\n",
        "\n",
        "# Download inputs\n",
        "download_from_gcs(BUCKET_NAME, INPUT_PLY_PATH, LOCAL_INPUT_PLY)\n",
        "download_from_gcs(BUCKET_NAME, INPUT_FEATURES_PATH, LOCAL_INPUT_FEATURES)\n",
        "\n",
        "pcd = o3d.io.read_point_cloud(LOCAL_INPUT_PLY)\n",
        "features = np.load(LOCAL_INPUT_FEATURES)\n",
        "points = np.asarray(pcd.points)\n",
        "\n",
        "print(f\"Loaded: {len(points):,} points\")\n",
        "print(f\"Features shape: {features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rule-based pre-labeling using Y_normalized\n",
        "# This is the key insight for 99.86% accuracy!\n",
        "\n",
        "print(\"\\nGenerating training labels using rule-based classification...\")\n",
        "print(\"Key insight: Y_normalized distinguishes elements by depth from facade\")\n",
        "\n",
        "# Extract normalized coordinates (last 3 columns of features)\n",
        "x_norm = features[:, -3]\n",
        "y_norm = features[:, -2]  # THE KEY FEATURE!\n",
        "z_norm = features[:, -1]\n",
        "\n",
        "# Initialize labels\n",
        "labels = np.zeros(len(points), dtype=np.int32)\n",
        "\n",
        "# Classification rules based on Y_normalized and Z_normalized\n",
        "# These thresholds were determined empirically from v6 local analysis\n",
        "\n",
        "# zemin (ground): low Z\n",
        "labels[z_norm < 0.15] = 0\n",
        "\n",
        "# seki (platform): front Y, low-mid Z\n",
        "labels[(y_norm > 0.6) & (z_norm < 0.35)] = 1\n",
        "\n",
        "# ana_cephe (main wall): back Y, mid Z\n",
        "labels[(y_norm < 0.4) & (z_norm > 0.15) & (z_norm < 0.85)] = 2\n",
        "\n",
        "# kemer (arch): front-mid Y, mid-high Z, curved region\n",
        "labels[(y_norm > 0.3) & (y_norm < 0.7) & (z_norm > 0.4) & (z_norm < 0.85)] = 3\n",
        "\n",
        "# sacak (cornice): high Z\n",
        "labels[z_norm > 0.85] = 4\n",
        "\n",
        "# Print distribution\n",
        "print(\"\\nInitial label distribution:\")\n",
        "for class_id, info in CLASSES.items():\n",
        "    count = np.sum(labels == class_id)\n",
        "    print(f\"  {info['name']}: {count:,} points ({100*count/len(labels):.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Train Random Forest\n",
        "print(\"\\nTraining Random Forest classifier...\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.15, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train):,} points\")\n",
        "print(f\"Test set: {len(X_test):,} points\")\n",
        "\n",
        "# Train model\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"CLASSIFICATION ACCURACY: {accuracy*100:.2f}%\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred, target_names=[c['name'] for c in CLASSES.values()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict all points\n",
        "print(\"\\nClassifying all points...\")\n",
        "final_labels = rf.predict(features)\n",
        "\n",
        "# Color points by class\n",
        "colors = np.zeros((len(points), 3))\n",
        "for class_id, info in CLASSES.items():\n",
        "    mask = final_labels == class_id\n",
        "    colors[mask] = np.array(info['color']) / 255.0\n",
        "\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# Print final distribution\n",
        "print(\"\\nFinal classification distribution:\")\n",
        "for class_id, info in CLASSES.items():\n",
        "    count = np.sum(final_labels == class_id)\n",
        "    print(f\"  {info['name']}: {count:,} points ({100*count/len(final_labels):.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save per-class PLY files\n",
        "print(\"\\nSaving per-class point clouds...\")\n",
        "\n",
        "for class_id, info in CLASSES.items():\n",
        "    mask = final_labels == class_id\n",
        "    if np.sum(mask) > 0:\n",
        "        class_pcd = pcd.select_by_index(np.where(mask)[0])\n",
        "        local_path = f\"/content/{info['name']}.ply\"\n",
        "        o3d.io.write_point_cloud(local_path, class_pcd)\n",
        "        upload_to_gcs(BUCKET_NAME, local_path, f\"{OUTPUT_BASE}{info['name']}.ply\")\n",
        "        print(f\"  {info['name']}: {np.sum(mask):,} points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "importances = rf.feature_importances_\n",
        "feature_names = [f\"f{i}\" for i in range(features.shape[1])]\n",
        "feature_names[-3:] = [\"x_normalized\", \"y_normalized\", \"z_normalized\"]\n",
        "\n",
        "# Top 10 features\n",
        "top_indices = np.argsort(importances)[::-1][:10]\n",
        "print(\"\\nTop 10 most important features:\")\n",
        "for i, idx in enumerate(top_indices):\n",
        "    print(f\"  {i+1}. {feature_names[idx]}: {importances[idx]*100:.2f}%\")\n",
        "\n",
        "# Stats\n",
        "stats = {\n",
        "    \"phase\": \"05_classification\",\n",
        "    \"accuracy\": float(accuracy),\n",
        "    \"accuracy_percent\": f\"{accuracy*100:.2f}%\",\n",
        "    \"n_points\": len(points),\n",
        "    \"n_classes\": len(CLASSES),\n",
        "    \"class_distribution\": {\n",
        "        info['name']: int(np.sum(final_labels == class_id))\n",
        "        for class_id, info in CLASSES.items()\n",
        "    },\n",
        "    \"top_features\": [\n",
        "        {\"name\": feature_names[idx], \"importance\": float(importances[idx])}\n",
        "        for idx in top_indices\n",
        "    ],\n",
        "    \"model_params\": {\n",
        "        \"n_estimators\": 100,\n",
        "        \"class_weight\": \"balanced\"\n",
        "    },\n",
        "    \"processing_time_sec\": elapsed_time,\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"pipeline_version\": \"v6\"\n",
        "}\n",
        "\n",
        "# Save model and stats\n",
        "joblib.dump(rf, LOCAL_OUTPUT_MODEL)\n",
        "with open(LOCAL_OUTPUT_JSON, 'w') as f:\n",
        "    json.dump(stats, f, indent=2)\n",
        "\n",
        "upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_MODEL, f\"{OUTPUT_BASE}05_model.joblib\")\n",
        "upload_to_gcs(BUCKET_NAME, LOCAL_OUTPUT_JSON, f\"{OUTPUT_BASE}05_classification_metrics.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Status for n8n\n",
        "status = {\n",
        "    \"phase\": \"05_classify\",\n",
        "    \"status\": \"success\",\n",
        "    \"version\": VERSION,\n",
        "    \"outputs\": {\n",
        "        \"model\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}05_model.joblib\",\n",
        "        \"metrics\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}05_classification_metrics.json\",\n",
        "        \"class_plys\": [f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}{info['name']}.ply\" for info in CLASSES.values()]\n",
        "    },\n",
        "    \"metrics\": {\n",
        "        \"accuracy\": f\"{accuracy*100:.2f}%\",\n",
        "        \"n_classes\": len(CLASSES),\n",
        "        \"processing_time\": f\"{elapsed_time:.1f}s\"\n",
        "    },\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"next_phase\": \"06_mesh\"\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 5 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(status, indent=2))"
      ]
    }
  ]
}
