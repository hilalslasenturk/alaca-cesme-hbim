{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 6: Mesh Reconstruction (Poisson + Trim)\n",
        "## Alaca Cesmesi Scan-to-HBIM V6 Pipeline\n",
        "\n",
        "Creates watertight meshes from classified point clouds using Poisson Surface Reconstruction.\n",
        "\n",
        "**Mesh Selection (from v6 analysis):**\n",
        "- zemin: trim 10%\n",
        "- seki: trim 5%\n",
        "- ana_cephe: no trim (original high quality)\n",
        "- kemer: no trim (original high quality)\n",
        "- sacak: trim 10%\n",
        "\n",
        "**Input:** `gs://alaca-cesme-hbim-v6/processed/v{N}/05_classification/`  \n",
        "**Output:** `gs://alaca-cesme-hbim-v6/processed/v{N}/06_mesh/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q open3d google-cloud-storage numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Configuration\n",
        "BUCKET_NAME = \"alaca-cesme-hbim-v6\"\n",
        "PROJECT_ID = \"concrete-racer-470219-h8\"\n",
        "VERSION = \"v1\"\n",
        "\n",
        "# Mesh parameters per element (from v6 analysis)\n",
        "ELEMENTS = {\n",
        "    \"zemin\": {\"depth\": 10, \"trim_pct\": 10, \"scale\": 1.1},\n",
        "    \"seki\": {\"depth\": 10, \"trim_pct\": 5, \"scale\": 1.1},\n",
        "    \"ana_cephe\": {\"depth\": 10, \"trim_pct\": 0, \"scale\": 1.1},\n",
        "    \"kemer\": {\"depth\": 10, \"trim_pct\": 0, \"scale\": 1.1},\n",
        "    \"sacak\": {\"depth\": 10, \"trim_pct\": 10, \"scale\": 1.1}\n",
        "}\n",
        "\n",
        "# Paths\n",
        "INPUT_BASE = f\"processed/{VERSION}/05_classification/\"\n",
        "OUTPUT_BASE = f\"processed/{VERSION}/06_mesh/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GCS functions\n",
        "def download_from_gcs(bucket_name, blob_name, local_path):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.download_to_filename(local_path)\n",
        "    print(f\"Downloaded: {blob_name}\")\n",
        "    return local_path\n",
        "\n",
        "def upload_to_gcs(bucket_name, local_path, blob_name):\n",
        "    client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_filename(local_path)\n",
        "    print(f\"Uploaded: {blob_name}\")\n",
        "    return f\"gs://{bucket_name}/{blob_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_poisson_mesh(pcd, depth=10, scale=1.1):\n",
        "    \"\"\"\n",
        "    Create Poisson surface reconstruction from point cloud.\n",
        "    \n",
        "    Args:\n",
        "        pcd: Point cloud with normals\n",
        "        depth: Octree depth (higher = more detail)\n",
        "        scale: Scale factor for bounding cube\n",
        "    \n",
        "    Returns:\n",
        "        mesh, densities\n",
        "    \"\"\"\n",
        "    # Ensure normals exist\n",
        "    if not pcd.has_normals():\n",
        "        pcd.estimate_normals(\n",
        "            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.05, max_nn=30)\n",
        "        )\n",
        "        pcd.orient_normals_consistent_tangent_plane(k=15)\n",
        "    \n",
        "    # Poisson reconstruction\n",
        "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
        "        pcd, depth=depth, scale=scale, linear_fit=False\n",
        "    )\n",
        "    \n",
        "    return mesh, np.asarray(densities)\n",
        "\n",
        "\n",
        "def trim_mesh(mesh, densities, trim_pct):\n",
        "    \"\"\"\n",
        "    Remove low-density vertices (trim the mesh).\n",
        "    \n",
        "    Args:\n",
        "        mesh: Input mesh\n",
        "        densities: Density values per vertex\n",
        "        trim_pct: Percentile threshold (0-100)\n",
        "    \n",
        "    Returns:\n",
        "        Trimmed mesh\n",
        "    \"\"\"\n",
        "    if trim_pct <= 0:\n",
        "        return mesh\n",
        "    \n",
        "    threshold = np.percentile(densities, trim_pct)\n",
        "    vertices_to_remove = densities < threshold\n",
        "    mesh.remove_vertices_by_mask(vertices_to_remove)\n",
        "    return mesh\n",
        "\n",
        "\n",
        "def fix_mesh_normals(mesh):\n",
        "    \"\"\"\n",
        "    Fix mesh normals to point outward from center.\n",
        "    \"\"\"\n",
        "    center = mesh.get_center()\n",
        "    triangles = np.asarray(mesh.triangles).copy()\n",
        "    vertices = np.asarray(mesh.vertices)\n",
        "    \n",
        "    fixed = 0\n",
        "    for i, tri in enumerate(triangles):\n",
        "        v0, v1, v2 = vertices[tri[0]], vertices[tri[1]], vertices[tri[2]]\n",
        "        face_center = (v0 + v1 + v2) / 3\n",
        "        normal = np.cross(v1 - v0, v2 - v0)\n",
        "        outward = face_center - center\n",
        "        \n",
        "        if np.dot(normal, outward) < 0:\n",
        "            triangles[i] = [tri[0], tri[2], tri[1]]\n",
        "            fixed += 1\n",
        "    \n",
        "    mesh.triangles = o3d.utility.Vector3iVector(triangles)\n",
        "    mesh.compute_vertex_normals()\n",
        "    \n",
        "    return mesh, fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "mesh_stats = {}\n",
        "\n",
        "for element_name, params in ELEMENTS.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing: {element_name.upper()}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Download point cloud\n",
        "    local_input = f\"/content/{element_name}.ply\"\n",
        "    try:\n",
        "        download_from_gcs(BUCKET_NAME, f\"{INPUT_BASE}{element_name}.ply\", local_input)\n",
        "    except Exception as e:\n",
        "        print(f\"  Skipping {element_name}: {e}\")\n",
        "        continue\n",
        "    \n",
        "    pcd = o3d.io.read_point_cloud(local_input)\n",
        "    n_points = len(pcd.points)\n",
        "    print(f\"  Loaded: {n_points:,} points\")\n",
        "    \n",
        "    # Create Poisson mesh\n",
        "    print(f\"  Creating Poisson mesh (depth={params['depth']})...\")\n",
        "    mesh, densities = create_poisson_mesh(pcd, depth=params['depth'], scale=params['scale'])\n",
        "    print(f\"  Raw mesh: {len(mesh.vertices):,} vertices, {len(mesh.triangles):,} triangles\")\n",
        "    \n",
        "    # Trim if needed\n",
        "    if params['trim_pct'] > 0:\n",
        "        print(f\"  Trimming (removing bottom {params['trim_pct']}% density)...\")\n",
        "        mesh = trim_mesh(mesh, densities, params['trim_pct'])\n",
        "        print(f\"  After trim: {len(mesh.vertices):,} vertices, {len(mesh.triangles):,} triangles\")\n",
        "    \n",
        "    # Fix normals\n",
        "    print(\"  Fixing normals...\")\n",
        "    mesh, fixed_count = fix_mesh_normals(mesh)\n",
        "    print(f\"  Fixed: {fixed_count:,} triangles ({100*fixed_count/len(mesh.triangles):.1f}%)\")\n",
        "    \n",
        "    # Clean mesh\n",
        "    mesh.remove_degenerate_triangles()\n",
        "    mesh.remove_duplicated_triangles()\n",
        "    mesh.remove_duplicated_vertices()\n",
        "    mesh.remove_non_manifold_edges()\n",
        "    \n",
        "    # Save\n",
        "    local_output = f\"/content/{element_name}_mesh.ply\"\n",
        "    o3d.io.write_triangle_mesh(local_output, mesh)\n",
        "    upload_to_gcs(BUCKET_NAME, local_output, f\"{OUTPUT_BASE}{element_name}_poisson.ply\")\n",
        "    \n",
        "    # Stats\n",
        "    mesh_stats[element_name] = {\n",
        "        \"input_points\": n_points,\n",
        "        \"vertices\": len(mesh.vertices),\n",
        "        \"triangles\": len(mesh.triangles),\n",
        "        \"depth\": params['depth'],\n",
        "        \"trim_pct\": params['trim_pct'],\n",
        "        \"normals_fixed\": fixed_count\n",
        "    }\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"\\nTotal processing time: {elapsed_time:.1f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MESH RECONSTRUCTION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n{'Element':<12} {'Points':>10} {'Vertices':>10} {'Triangles':>10} {'Trim':>6}\")\n",
        "print(\"-\"*50)\n",
        "for name, stats in mesh_stats.items():\n",
        "    print(f\"{name:<12} {stats['input_points']:>10,} {stats['vertices']:>10,} {stats['triangles']:>10,} {stats['trim_pct']:>5}%\")\n",
        "\n",
        "# Save stats\n",
        "final_stats = {\n",
        "    \"phase\": \"06_mesh\",\n",
        "    \"meshes\": mesh_stats,\n",
        "    \"processing_time_sec\": elapsed_time,\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"pipeline_version\": \"v6\"\n",
        "}\n",
        "\n",
        "local_stats = \"/content/06_mesh_stats.json\"\n",
        "with open(local_stats, 'w') as f:\n",
        "    json.dump(final_stats, f, indent=2)\n",
        "upload_to_gcs(BUCKET_NAME, local_stats, f\"{OUTPUT_BASE}06_mesh_stats.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Status for n8n\n",
        "status = {\n",
        "    \"phase\": \"06_mesh\",\n",
        "    \"status\": \"success\",\n",
        "    \"version\": VERSION,\n",
        "    \"outputs\": {\n",
        "        \"meshes\": [f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}{name}_poisson.ply\" for name in mesh_stats.keys()],\n",
        "        \"stats\": f\"gs://{BUCKET_NAME}/{OUTPUT_BASE}06_mesh_stats.json\"\n",
        "    },\n",
        "    \"metrics\": {\n",
        "        \"n_meshes\": len(mesh_stats),\n",
        "        \"total_triangles\": sum(s['triangles'] for s in mesh_stats.values()),\n",
        "        \"processing_time\": f\"{elapsed_time:.1f}s\"\n",
        "    },\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"next_phase\": \"07_ifc\"\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 6 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(status, indent=2))"
      ]
    }
  ]
}
